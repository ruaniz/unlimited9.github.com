# 케라스 창시자에게 배우는 딥러닝

## 1. 딥러닝이란 무엇인가?

### 1.1 인공 지능과 머신 러닝, 딥러닝
AI(artificial intelligence) > ML(machine learning) > DL(deep learning)

#### 1.1.1 인공지능 : AI(artificial intelligence)
보통의 사람이 수행하는 지능적인 작업을 자동화하기 위한 연구 활동  
어떤 것을 작동시키기 위해 우리가 알고 있는 것 이상으로 컴퓨터가 처리하는 것이 가능한가.
- 심볼릭 AI(symbolic AI)
- 전문가 시스템(expert system)
- 머신 러닝입(machine learning)

#### 1.1.2 머신 러닝 : ML(machine learning)
데이터, 규칙 => 결과 : traditional programming 
데이터, 결과 => 규칙 : machine learningl, training

#### 1.1.3 데이터에서 표현을 학습하기
- 입력 데이터 포인트 : 분석 대상 데이터
- 기대 출력 : 목표 결과
- 알고리즘의 성능을 측정 : 알고리즘의 현재 출력과 기대 출력 간의 차이를 결정  
측정값은 알고리즘의 작동 방식을 교정하기 위한 신호로 다시 피드백되고, 이런 수정 단계를 학습(learning) 이라고 한다.

.머신 러닝에서의 학습Learning이란 더 나은 표현을 찾는 자동화된 과정
.입력 데이터를 의미 있는 데이터로 변환(표현, representation) : machine learning model
.분석을 위헤 데이터를 더 유용한 표현으로 변환 : 좌표변환, 선형 투영(lineal projection), 이동(translation), 비선형 연산 등 
.머신러닝은 변환에 대한 창의력은 없고 가설 공간(hypothesis space)에 정의된 연산 모음을 활용/조사

#### 1.1.4 딥러닝에서 ‘딥’이란 무엇일까? : DL(deep learning)
연속된 층(layer)에서 점진적으로 의미 있는 표현 학습
층 기반 표현 학습(layered representations learning)
계층적 표현 학습(hierarchical representations learning)

cf. 얕은 학습(shallow learning) : 1~2개의 데이터 표현 층을 학습

`신경망(neural network) 모델`
  기본 층을 겹겹이 쌓아 올려 구성

  ref. 인공 신경망(artificial neural network), 생물학적 신경망(biological neural network)

  .뇌 구조에서 영감을 얻어 개발되었으나 딥러닝 모델에서 사용하는 학습 메커니즘과 유사한것이 뇌에 있거나 딥러닝이 뇌를 기반으로 모델링하여 비슷하게 작동하게 작동하는 것은 아니다.
  .신경망 모델을 생물할적 신경망과 연관짓기 보다는 데이터로 부터 표현을 학습하는 수학 모델

  심층 신경망 : 정보가 연속된 필터(filter)를 통과하면서 요구 작업/분석에 대해서 유용하도록 정제되는 다단계 정보 추출 작업

DL은 데이터 표현을 학습하기 위한 다단계 처리 방식

#### 1.1.5 그림 3개로 딥러닝의 작동 원리 이해하기

.입력(input data), 목표 결과(target), 맵핑(mapping) : 
.층(layer) = 데이터 변환 with parameter:가중치(weight)
.가중치(weight) : 층(layer) 파라미터 or 모델(model) 파라미터 
.손실 함수(loss function)/비용 함수(cost function), 목적 함수(objective function)

역전파(backpropagation) 알고리즘을 구현한 옵티마이저(optimizer)는
입력된 데이터를 
1. 층(layer, 데이터 변환)별 가중치(weight)를 적용해 예측(변환)하고
2. 예측(변환) 결과와 목표 결과(target)와 비교/관찰하고
3. 손실 함수를 통해 출력 품질을 측정하여 (차이를 수치화 : 손실점수)
4. 손실 점수가 감소하는 방향으로 가중치를 수정하여
5. 훈련 반복(training loop)  
가중치가 처음에는 random으로 할당되어 손실 점수가 높지만 다양한 샘플을 반복 수행하면서 올바른 방향으로 가중치가 조정되어 손실 점수가 감소  
일반적으로 수천개의 샘풀로 수십번 반복하여 최소한의 손실을 내는 모델이 된다.  


#### 1.1.6 지금까지 딥러닝의 성과
#### 1.1.7 단기간의 과대 선전을 믿지 말자
#### 1.1.8 AI에 대한 전망
단기간의 과대 선전은 믿지 말고 장기 비전을 믿으세요.  
AI가 아직 아무도 감히 생각하지도 못했던 완전한 모습으로 진정한 잠재성을 발휘하려면 어느 정도의 시간이 걸릴지 아무도 모릅니다.  
하지만 AI의 시대는 올 것이고 이 세상을 환상적인 방식으로 변모시킬 것입니다.

### 1.2 딥러닝 이전: 머신 러닝의 간략한 역사

#### 1.2.1 확률적 모델링 : probabilistic modeling
통계학 이론을 데이터 분석 응용으로 초창기 머신 러닝 형태 중 하나고 요즘도 널리 사용

`분류 연산 방식(classification algorithm)`  
- 나이브 베이즈(Naive Bayes)  
입력 데이터의 특성이 모두 독립적이라고 가정하고 베이즈 정리(Bayes’ theorem)를 적용하는 머신 러닝 분류 알고리즘
- 로지스틱 회귀(logistic regression)  
간단하고 다목적으로 활용할 수 있어서 오늘날에도 여전히 유용하며, 데이터 과학자가 분류 작업에 대한 감을 빠르게 얻기 위해 데이터셋에 적용할 첫 번째 알고리즘으로 선택하는 경우가 많음.
(회귀 알고리즘이 아닌 분류 알고리즘. 이름 때문에 혼통하지 말자.)

#### 1.2.2 초창기 신경망
역전파 알고리즘을 재발견하고 신경망에 이를 적용하기 시작하면서 상황이 전환
역전파(backpropagation 알고리즘 : 경사 하강법 최적화를 사용하여 연쇄적으로 변수가 연결된 연산을 훈련하는 방법

#### 1.2.3 커널 방법 : Kernel method
분류 연산 방식(classification algorithm)으로 고차원 비선형 투영(Support Vector Machine, SVM)이 가장 유명(SVM은 분류 뿐아니라 회귀 문제에도 사용가능)
SVM은 2개의 다른 범주에 속한 데이터 포인트 그룹 사이에 좋은 결정 경계(decision boundary)를 찾아 분류

SVM이 결정 경계를 찾는 과정
1. 결정 경계가 하나의 초평면(hyperplane)으로 표현될 수 있는 새로운 고차원 표현으로 데이터를 매핑 (2차원 데이터라면 초평면은 직선)
2. 초평면과 각 클래스의 가장 가까운 데이터 포인트 사이의 거리가 최대가 되는 최선의 결정 경계(하나의 분할 초평면)를 찾기.  
  (이 단계를 마진 최대화(maximizing the margin)라고 하며, 이를 통해 결정 경계가 훈련 데이터셋 이외의 새로운 샘플에 잘 일반화되도록 한다.)

분류 문제를 간단하게 만들어 주기 위해 데이터를 고차원 표현으로 매핑하는 기법이 이론상으로는 좋아보이지만 실제로는 컴퓨터로 구현하기 어려움
그래서 커널 기법(kernel trick)이 등장(커널 방법의 핵심 아이디어)
새롭게 표현된 공간에서 좋은 결정 초평면을 찾기 위해 새로운 공간에 대응하는 데이터 포인트의 좌표를 실제로 구할 필요가 없습니다.
새로운 공간에서의 두 데이터 포인트 사이의 거리를 계산할 수만 있으면 됩니다. 커널 함수(kernel function)를 사용하면 이를 효율적으로 계산할 수 있습니다.
커널 함수는 원본 공간에 있는 두 데이터 포인트를 명시적으로 새로운 표현으로 변환하지 않고 타깃 표현 공간에 위치했을 때의 거리를 매핑해 주는 계산 가능한 연산입니다.
커널 함수는 일반적으로 데이터로부터 학습되지 않고 직접 만들어야 합니다. SVM에서 학습되는 것은 분할 초평면뿐입니다.

SVM이 개발되었을 때 간단한 분류 문제에 대해 최고 수준의 성능을 달성했고 광범위한 이론으로 무장된 몇 안 되는 머신 러닝 방법 중 하나가 되었습니다.
또 수학적으로 깊게 분석하기 용이하여 이론을 이해하고 설명하기 쉽습니다.
이런 유용한 특징 때문에 SVM이 오랫동안 머신 러닝 분야에서 매우 큰 인기를 끌었습니다.

하지만 SVM은 대용량의 데이터셋에 확장되기 어렵고 이미지 분류 같은 지각에 관련된 문제에서 좋은 성능을 내지 못했습니다.
SVM은 얕은 학습 방법이기 때문에 지각에 관련된 문제에 SVM을 적용하려면 먼저 수동으로 유용한 표현을 추출해야 하는데(이런 단계를 특성 공학(feature engineering)이라고 합니다) 이는 매우 어렵고 불안정합니다.

#### 1.2.4 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 머신

- 결정 트리(decision tree)
플로차트flowchart 같은 구조를 가지며 입력 데이터 포인트를 분류하거나 주어진 입력에 대해 출력 값을 예측
결정 트리는 시각화하고 이해하기 쉽다.

- 랜덤 포레스트(Random Forest)
결정 트리 학습에 기초한 것으로 안정적이고 실전에서 유용
서로 다른 결정 트리를 많이 만들고 그 출력을 앙상블하는 방법을 사용
랜덤 포레스트는 다양한 문제에 적용할 수 있고 얕은 학습에 해당하는 어떤 작업에서도 거의 항상 두 번째로 가장 좋은 알고리즘입니다.
잘 알려진 머신 러닝 경연 웹 사이트인 캐글(Kaggle)(http://kaggle.com)이 2010년에 시작되었을 때부터 랜덤 포레스트가 가장 선호하는 알고리즘이 되었습니다. 

- 그래디언트 부스팅 머신(gradient boosting machine)
랜덤 포레스트와 아주 비슷하게 그래디언트 부스팅 머신은 약한 예측 모델인 결정 트리를 앙상블하는 것을 기반으로 하는 머신 러닝 기법
이 알고리즘은 이전 모델에서 놓친 데이터 포인트를 보완하는 새로운 모델을 반복적으로 훈련함으로써 머신 러닝 모델을 향상하는 방법인 그래디언트 부스팅(gradient boosting)을 사용합니다.
결정 트리에 그래디언트 부스팅 기법을 적용하면 비슷한 성질을 가지면서도 대부분의 경우에 랜덤 포레스트의 성능을 능가하는 모델을 만듭니다.
이 알고리즘이 오늘날 지각에 관련되지 않은 데이터를 다루기 위한 알고리즘 중 최고는 아니지만 가장 뛰어납니다.
딥러닝을 제외하고 캐글 경연 대회에서 가장 많이 사용되는 기법입니다.

#### 1.2.5 다시 신경망으로
- 심층 신경망(deep neural network)  
- 심층 합성곱 신경망(deep convolutional neural network, ConvNet)  

#### 1.2.6 딥러닝의 특징
이전의 머신 러닝 기법은 머신 러닝 방법들로 처리하기 용이하게 사람이 초기 입력 데이터를 여러 방식으로 변환 필요.  
(데이터의 좋은 표현을 수동으로 생성, 특성 공학(feature engineering))  
딥러닝은 이 단계를 자동화하여 특성을 직접 찾는 대신 한 번에 모든 특성을 학습  
이는 머신 러닝 작업 흐름을 매우 단순화시켜 고도의 다단계 작업 과정을 하나의 간단한 엔드-투-엔드(end-to-end) 딥러닝 모델로 대체 가능  

딥러닝의 변환 능력은 모델이 모든 표현 층을 순차적(탐욕적, greedily) 방법이 아니라 동시에 공동으로 학습  

딥러닝이 데이터로부터 학습하는 방법의 두 가지 중요한 특징  
층을 거치면서 점진적으로 더 복잡한 표현이 만들어진다는 것과 이런 점진적인 중간 표현이 공동으로 학습된다는 사실입니다.  
각 층은 상위 층과 하위 층의 표현이 변함에 따라서 함께 바뀝니다.  
이 2개의 특징이 이전의 머신 러닝 접근 방법보다 딥러닝이 훨씬 성공하게 된 이유입니다.

#### 1.2.7 머신 러닝의 최근 동향
오늘날 머신 러닝을 성공적으로 적용하기 위해 알아야 할 두 가지 기술
- 얕은 학습 문제를 위한 그래디언트 부스팅 머신 : XGBoost  
- 지각에 관한 문제를 위한 딥러닝 : 케라스  



## 9. Appendix

#### reference site

+ 텐서 플로우 블로그 (Tensor ≈ Blog)  
https://tensorflow.blog

+ 텐서 플로우 블로그 (Tensor ≈ Blog)/케라스 딥러닝  
https://tensorflow.blog/%ec%bc%80%eb%9d%bc%ec%8a%a4-%eb%94%a5%eb%9f%ac%eb%8b%9d/



>
>
>
>
>
>
>
>




## 대규모 데이터 마이닝을 위한 머신 러닝 및 딥 러닝 프레임 워크 및 라이브러리

#### 데이터 마이닝 (DM)
데이터에서 흥미롭고 잠재적으로 유용한 정보를 추출하는 것을 목표로하는 지식 발견 프로세스의 핵심 단계

#### Artificial Intelligence (AI) : 인공 지능
컴퓨터 학습, 자연어 처리 (NLP), 언어 합성, 컴퓨터 비전, 로봇 공학, 센서 분석, 최적화 및 시뮬레이션 등  
컴퓨터가 인간의 행동을 모방 할 수 있도록하는 기술

#### Machine Learning (ML) : 기계 학습
컴퓨터 시스템이 이전 경험 (예 : 데이터 관찰)을 통해 학습하고 주어진 작업에 대한 동작을 개선 할 수 있도록하는 AI 기술의 하위 집합  
ML 기술에는 SVM (Support Vector Machine), 의사 결정 트리, Bayes 학습, k- 평균 군집화, 연관 규칙 학습, 회귀, 신경망 등이 포함

#### (artificial) Neural Networks (NN) : (인공) 신경망
생물학적 신경망에서 느슨하게 영감을 얻은 ML 기술의 하위 집합  
보통 층으로 구성된 인공 뉴런이라고 불리는 연결된 유닛의 집합으로 묘사

#### Deep Learning (DL) : 심층 학습
계산 멀티 레이어 NN을 실현할 수있는 NN의 하위 집합  
일반적인 DL 아키텍처 : DNN (Deep Neural Network), CNN (Convolutional Neural Network), RNN (Recurrent Neural Network), GAN (Generative Adversarial Network) 등


